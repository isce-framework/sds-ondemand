{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\">Copyright 2021, by the California Institute of Technology. ALL RIGHTS RESERVED. United States Government sponsorship acknowledged. Any commercial use must be negotiated with the Office of Technology Transfer at the California Institute of Technology.</font>\n",
    "    \n",
    "<font size=\"1\">This software may be subject to U.S. export control laws and regulations. By accepting this document, the user agrees to comply with all applicable U.S. export laws and regulations. User has the responsibility to obtain export licenses, or other export authority as may be required, before exporting such information to foreign countries or providing access to foreign persons.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small baseline InSAR time series analysis with smallbaselineApp #\n",
    "\n",
    "#### Kernel: mintpy\n",
    "\n",
    "There are two groups of InSAR time series techniques: persistent scatterer (PS) methods, which focus on the phase-stable point scatterers, and distributed scatterer (DS) methods, which relaxed the strict limit on the phase stability and included areas that are affected by decorrelation through the exploitation of the redundant network of interferograms. In this notebook we focus on the DS method, and more specifically, the DS method with the network of small baseline interferograms (SBAS) using smallbaselineApp.py\n",
    "\n",
    "The detailed algorithms and mathematical formulations implemented in MintPy software can be found in the literature:\n",
    "\n",
    "+ Yunjun, Z., H. Fattahi, F. Amelung (2019), Small baseline InSAR time series analysis: Unwrapping error correction and noise reduction, Computers & Geosciences, 133, 104331, doi:[10.1016/j.cageo.2019.104331](https://doi.org/10.1016/j.cageo.2019.104331), [arXiv](https://eartharxiv.org/9sz6m/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smallbaselineApp (general overview) #\n",
    "\n",
    "smallbaselineApp.py is a MintPy script for the routine processing workflow of InSAR time series analysis. The script takes a stack of coregistered and unwrapped interferograms and generates the displacement time-series. The workflow consists of two main blocks:   \n",
    "+ correcting unwrapping errors and inverting for the raw phase time-series (blue ovals),   \n",
    "+ correcting for noise from different sources to obtain the displacement time-series (green ovals).    \n",
    "\n",
    "Some steps are optional, which are switched off by default (marked by dashed boundaries). Configuration parameters for each step are initiated with default values in a customizable text file: [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg). In this notebook, we will walk through the various steps.      \n",
    "     \n",
    "<p align=\"left\">\n",
    "  <img width=\"600\" src=\"support_docs/smallbaselineApp/smallbaselineApp_workflow.png\">\n",
    "</p>     \n",
    "<p style=\"text-align: center;\">\n",
    "    (Figure from Yunjun et al., 2019)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is a stack of **phase-unwrapped** interferograms **coregistered to a common SAR acquisition**, corrected for earth curvature and topography, which are referred hereafter as a **InSAR stack**. MintPy currently supports InSAR stacks produced by ISCE, GAMMA and ROI_PAC software (Rosen et al., 2004; 2012; Werner et al., 2000) with example data directories shown [here](https://mintpy.readthedocs.io/en/latest/dir_structure/).\n",
    "\n",
    "### Example dataset ###\n",
    "Here we use the InSAR stack from Sentinel-1 satellite descending track 128 acquired over Fernandina volcano, Galapagos, Ecuador as an example ([Zenodo](https://zenodo.org/record/3635245); ~750M in size). It spans from 2014-12-13 to 2018-06-19 with 98 acquisitions in total. We use the stack Sentinel processor (Fattahi et al., 2016) within ISCE (Rosen et al., 2012) for processing the InSAR stack.     \n",
    "\n",
    "<p align=\"left\">\n",
    "  <img src=\"support_docs/smallbaselineApp/FernandinaSenDT128_unwrapPhase_wrap.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial setup of the notebook ##\n",
    "\n",
    "The cell below performs the intial setup of the notebook and **must be run every time the notebook (re)starts**. It defines the processing location and check the example dataset. It is possible to partially complete the exercise, close the notebook, and come back and continue later from that point, but this initialization must be re-run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mintpy.objects import ifgramStack\n",
    "from mintpy.utils import plot as pp, utils as ut\n",
    "from mintpy import view, plot_network\n",
    "\n",
    "# this block makes sure the directory set-up/change is only done once and relative to the notebook's directory\n",
    "try:\n",
    "    start_dir\n",
    "except NameError:\n",
    "    start_dir = os.getcwd()\n",
    "\n",
    "# define work directory\n",
    "work_dir = os.path.join(start_dir, 'notebook_output/smallbaselineApp/data/test')\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "print('Go to work directory: {}'.format(work_dir))\n",
    "\n",
    "# download example dataset\n",
    "proj_name = 'FernandinaSenDT128'\n",
    "tar_file = '{}.tar.xz'.format(proj_name)\n",
    "if not os.path.isfile(tar_file):\n",
    "    !wget https://zenodo.org/record/3635245/files/FernandinaSenDT128.tar.xz\n",
    "else:\n",
    "    print('{} exists.'.format(tar_file))\n",
    "\n",
    "# uncompress example dataset\n",
    "if not os.path.isdir(proj_name):\n",
    "    cmd = 'tar -xJf FernandinaSenDT128.tar.xz'\n",
    "    print('uncompressing the tar file:', cmd, '...')\n",
    "    !{cmd}\n",
    "\n",
    "# go to project directory\n",
    "proj_dir = os.path.join(work_dir, '{}/mintpy'.format(proj_name))\n",
    "os.chdir(proj_dir)\n",
    "print('Go to project directory: {}'.format(proj_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up template file ##\n",
    "\n",
    "The configuration parameters to smallbaselineApp.py are controlled through two template files. At least one template is required to run smallbaselineApp.py.    \n",
    "\n",
    "+ `default template`: [smallbaselineApp.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp.cfg). It contains all configuration parameters, grouped by steps, with default _auto_ values (which are defined in [smallbaselineApp_auto.cfg](https://github.com/insarlab/MintPy/blob/master/mintpy/defaults/smallbaselineApp_auto.cfg)). This file is copied over to the current working directory and read every time smallbaselineApp.py runs.\n",
    "\n",
    "\n",
    "+ `custom template` (optional but recommended): FernandinaSenDT128.txt in the example dataset. It constains selective, manually modified configuration parameters. The custome template file name is arbitrary. Custom template has higher priority than the default template; if custom template is input, smallbaselineApp.py will update the default smallbaselineApp.cfg file accordingly.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom template example ###\n",
    "\n",
    "The path of all input files (`mintpy.load.*`) and the reference point (`mintpy.reference.*`) are always recommended. Below are from FernandinaSenDT128.txt file: \n",
    "\n",
    "```cfg\n",
    "########## 1. Load Data (--load to exit after this step)\n",
    "## load_data.py -H to check more details and example inputs.\n",
    "mintpy.load.processor        = isce\n",
    "##---------for ISCE only:\n",
    "mintpy.load.metaFile         = ../master/IW*.xml\n",
    "mintpy.load.baselineDir      = ../baselines\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile          = ../merged/interferograms/*/filt_*.unw\n",
    "mintpy.load.corFile          = ../merged/interferograms/*/filt_*.cor\n",
    "mintpy.load.connCompFile     = ../merged/interferograms/*/filt_*.unw.conncomp\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = ../merged/geom_master/hgt.rdr\n",
    "mintpy.load.lookupYFile      = ../merged/geom_master/lat.rdr\n",
    "mintpy.load.lookupXFile      = ../merged/geom_master/lon.rdr\n",
    "mintpy.load.incAngleFile     = ../merged/geom_master/los.rdr\n",
    "mintpy.load.azAngleFile      = ../merged/geom_master/los.rdr\n",
    "mintpy.load.shadowMaskFile   = ../merged/geom_master/shadowMask.rdr\n",
    "mintpy.load.waterMaskFile    = None\n",
    "\n",
    "mintpy.reference.lalo        = -0.30,-91.43\n",
    "mintpy.topographicResidual.stepFuncDate  = 20170910,20180613  #eruption dates\n",
    "mintpy.deramp                = linear\n",
    "```\n",
    "    \n",
    "Check **more examples for custom template** on [here](https://github.com/insarlab/MintPy/tree/master/docs/examples/input_files).      \n",
    "Run **load_data.py -H** for example input file paths for GAMMA and ROI_PAC.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. smallbaselineApp.py processing steps ##\n",
    "\n",
    "The smallbaselineApp.py workflow can be called with a single command-line call; by default it will run all the required processing steps with options pulled from the template files. However, in this notebook, we will use the \"step\" processing, this allows you to re-start the processing from a given step. More detailed usage can be found in help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the InSAR stack ###\n",
    "\n",
    "This step prepares the required metadata (using prep_isce/gamma/roipac.py commands internally) and load all data files and their metadata into HDF5 files in the **./inputs** folder, including:\n",
    "```cfg\n",
    "./inputs/ifgramStack.h5\n",
    "./inputs/geometryRadar.h5\n",
    "./inputs/geometryGeo.h5 #for geocoded dataset or GAMMA/ROIPAC dataset in radar coordinates\n",
    "```\n",
    "\n",
    "The corresponding template options are:\n",
    "```cfg\n",
    "########## 1. load_data\n",
    "## a. auto - automatic path pattern for Univ of Miami file structure\n",
    "## b. load_data.py -H to check more details and example inputs.\n",
    "## c. compression to save disk usage for ifgramStack.h5 file:\n",
    "## no   - save   0% disk usage, fast [default]\n",
    "## lzf  - save ~57% disk usage, relative slow\n",
    "## gzip - save ~62% disk usage, very slow [not recommend]\n",
    "mintpy.load.processor      = auto  #[isce, aria, snap, gamma, roipac], auto for isce\n",
    "mintpy.load.updateMode     = auto  #[yes / no], auto for yes, skip re-loading if HDF5 files are complete\n",
    "mintpy.load.compression    = auto  #[gzip / lzf / no], auto for no.\n",
    "##---------for ISCE only:\n",
    "mintpy.load.metaFile       = auto  #[path of common metadata file for the stack], i.e.: ./master/IW1.xml, ./masterShelve/data.dat\n",
    "mintpy.load.baselineDir    = auto  #[path of the baseline dir], i.e.: ./baselines\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile        = auto  #[path pattern of unwrapped interferogram files]\n",
    "mintpy.load.corFile        = auto  #[path pattern of spatial coherence       files]\n",
    "mintpy.load.connCompFile   = auto  #[path pattern of connected components    files], optional\n",
    "mintpy.load.intFile        = auto  #[path pattern of wrapped interferogram   files], optional\n",
    "mintpy.load.ionoFile       = auto  #[path pattern of ionospheric delay       files], optional\n",
    "##---------offset datasets (optional):\n",
    "mintpy.load.azOffFile      = auto  #[path pattern of azimuth offset file], optional\n",
    "mintpy.load.rgOffFile      = auto  #[path pattern of range   offset file], optional\n",
    "mintpy.load.offSnrFile     = auto  #[path pattern of offset signal-to-noise ratio file], optional\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile        = auto  #[path of DEM file]\n",
    "mintpy.load.lookupYFile    = auto  #[path of latitude /row   /y coordinate file], not required for geocoded data\n",
    "mintpy.load.lookupXFile    = auto  #[path of longitude/column/x coordinate file], not required for geocoded data\n",
    "mintpy.load.incAngleFile   = auto  #[path of incidence angle file], optional\n",
    "mintpy.load.azAngleFile    = auto  #[path of azimuth   angle file], optional\n",
    "mintpy.load.shadowMaskFile = auto  #[path of shadow mask file], optional\n",
    "mintpy.load.waterMaskFile  = auto  #[path of water  mask file], optional\n",
    "mintpy.load.bperpFile      = auto  #[path pattern of 2D perpendicular baseline file], optional\n",
    "##---------subset (optional):\n",
    "## if both yx and lalo are specified, use lalo option unless a) no lookup file AND b) dataset is in radar coord\n",
    "mintpy.subset.yx   = auto    #[1800:2000,700:800 / no], auto for no\n",
    "mintpy.subset.lalo = auto    #[31.5:32.5,130.5:131.0 / no], auto for no\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l inputs                      #check loaded files in ./INPUTS directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ./inputs/ifgramStack.h5 ####\n",
    "\n",
    "The ./inputs/ifgramStack.h5 file contains all unwrapped phase, spatial coherence, connected components (generated by SNAPHU) and the auxiliary data including the perpendicular baseline and dates for each interferogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py inputs/ifgramStack.h5     #use info.py / gdalinfo to check the HDF5 file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all data related with one interferometric pair\n",
    "view.main('./inputs/ifgramStack.h5 20180315_20180327 --ncols 3'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ./inputs/geometry*.h5 ####\n",
    "\n",
    "The ./inputs/geometryRadar.h5 file contains all geometry related data, including height, latitude, longitude, incidence angle, etc. If these files are in geo coordinates, then the output file will be geometryGeo.h5.\n",
    "\n",
    "Note that for **ISCE**, the lookup files (`lat.rdr and lon.rdr`) are in radar coordinates and are loaded into ./inputs/geometryRadar.h5 file as \"latitude\" and \"longitude\" dataset; while **GAMMA and ROI_PAC** lookup files (`sim*.UTM_TO_RDC and geomap*.trans`) are in geo coordinates and are loaded into ./inputs/geometryGeo.h5 file as \"azimuthCoord\" and \"rangeCoord\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py ./inputs/geometryRadar.h5 --compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('./inputs/geometryRadar.h5'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Network modification (optional) ###\n",
    "\n",
    "This step identifies and excludes interferograms (i.e. affected by remaining coherence phase-unwrapping errors) before the network inversion. This is done by setting the corresponding dataset `dropIfgram = False` in ./inputs/ifgramStack.h5 file. The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "########## 2. modify_network\n",
    "## reference: Yunjun et al. (2019, section 4.2 and 5.3.1)\n",
    "## 1) Coherence-based network modification = (threshold + MST) by default\n",
    "## It calculates a average coherence value for each interferogram using spatial coherence and input mask\n",
    "## Then it finds a minimum spanning tree (MST) network with inverse of average coherence as weight\n",
    "## For all interferograms except for MST's, exclude those with average coherence < minCoherence.\n",
    "mintpy.network.coherenceBased  = auto  #[yes / no], auto for no, exclude interferograms with coherence < minCoherence\n",
    "mintpy.network.keepMinSpanTree = auto  #[yes / no], auto for yes, keep interferograms in Min Span Tree network\n",
    "mintpy.network.minCoherence    = auto  #[0.0-1.0], auto for 0.7\n",
    "mintpy.network.maskFile        = auto  #[file name, no], auto for waterMask.h5 or no [if no waterMask.h5 found]\n",
    "mintpy.network.aoiYX           = auto  #[y0:y1,x0:x1 / no], auto for no, area of interest for coherence calculation\n",
    "mintpy.network.aoiLALO         = auto  #[lat0:lat1,lon0:lon1 / no], auto for no - use the whole area\n",
    "\n",
    "## 2) Network modification based on temporal/perpendicular baselines, date etc.\n",
    "mintpy.network.tempBaseMax     = auto  #[1-inf, no], auto for no, max temporal baseline in days\n",
    "mintpy.network.perpBaseMax     = auto  #[1-inf, no], auto for no, max perpendicular spatial baseline in m\n",
    "mintpy.network.connNumMax      = auto  #[1-inf, no], auto for no, max number of neighbors for each acquisition\n",
    "mintpy.network.startDate       = auto  #[20090101 / no], auto for no\n",
    "mintpy.network.endDate         = auto  #[20110101 / no], auto for no\n",
    "mintpy.network.excludeDate     = auto  #[20080520,20090817 / no], auto for no\n",
    "mintpy.network.excludeIfgIndex = auto  #[1:5,25 / no], auto for no, list of ifg index (start from 0)\n",
    "mintpy.network.referenceFile   = auto  #[date12_list.txt / ifgramStack.h5 / no], auto for no\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>TIP:</b> \n",
    "For coherence-based network modification, a customized area of interest (AOI) that includes the low coherent areas surrounding the areas with coherent phase-unwrapping error is highly recommended. Such as the blue rectangle in the figure below.\n",
    "</div>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=600, src=\"support_docs/smallbaselineApp/net_modification.jpg\">\n",
    "</p>    \n",
    "<p style=\"text-align: center;\">\n",
    "    (Figure from Yunjun et al., 2019)\n",
    "</p>    \n",
    "\n",
    "In this dataset, we turn off (by default) this option and skip this step, becuase there is no remaining phase-unwrapping error on coherent pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep modify_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot network ####\n",
    "\n",
    "The network configuration information is plotted and saved into the following files:\n",
    "\n",
    "+ Network.pdf: network configuration in temporal and perpendicular baseline plane.\n",
    "+ CoherenceMatrix.pdf: average spatial coherence of each interferogram.\n",
    "+ CoherenceHistory.pdf: the min/max average spatial coherence of all interferograms for each acquisition.\n",
    "+ BperpHistory.pdf: the perpendicular spatial baseline history of the dataset.\n",
    "\n",
    "The network configuartion and coherence matrix is re-plotted in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_network.main(['./inputs/ifgramStack.h5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Select reference point ###\n",
    "\n",
    "This step adds the reference point information into the **./inputs/ifgramStack.h5** by adding the metadata **REF_Y/X** (and REF_LAT/LON if input dataset is geocoded). The reference point should have valid phase (not NaN or zero) in all interferograms.    \n",
    "\n",
    "The reference pixel can be selected in two ways:\n",
    "1. randomly among the pixels with high average spatial coherence (default threshold is 0.85).\n",
    "2. specified using prior knowledge of the study area `(recommended)`. The reference pixel should be:\n",
    "   1. located in a coherent area;\n",
    "   2. not be affected by strong atmospheric turbulence such as ionospheric streaks; \n",
    "   3. close to and with similar elevation as the area of interest to minimize the impact of the spatially correlated atmospheric delay. For example, Chaussard et al. (2013) and Morales-Rivera et al. (2016) studied volcano deformation using reference points on inactive, neighboring volcanoes.  \n",
    "   \n",
    "The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "## reference all interferograms to one common point in space\n",
    "## auto - randomly select a pixel with coherence > minCoherence\n",
    "mintpy.reference.yx            = auto   #[257,151 / auto]\n",
    "mintpy.reference.lalo          = auto   #[31.8,130.8 / auto]\n",
    "mintpy.reference.maskFile      = auto   #[filename / no], auto for maskConnComp.h5\n",
    "mintpy.reference.coherenceFile = auto   #[filename], auto for avgSpatialCoh.h5\n",
    "mintpy.reference.minCoherence  = auto   #[0.0-1.0], auto for 0.85, minimum coherence for auto method\n",
    "```\n",
    "   \n",
    "This step also generates the following auxiliary files:\n",
    "+ avgSpatialCoh.h5: the average spatial coherence among all interferograms.\n",
    "+ maskSpatialCoh.h5 : mask file from the average spatial coherence with min value of 0.7\n",
    "+ maskConnComp.h5: the common connected components among all interferograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep reference_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py ./inputs/ifgramStack.h5 | egrep 'REF_'    #attribute related to the reference point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Quick overview ###\n",
    "\n",
    "This step generates the following two files:\n",
    "\n",
    "+ avgPhaseVelocity.h5: the average phase velocity using traditional stacking technique (Zebker et al., 1997) by dividing the unwrapped interferometric phase by their temporal baselines and averaging all interferograms. It provides a **quick assessment** of possible ground deformation.\n",
    "\n",
    "+ numNonzeroIntClosure.h5: the number of interferogram triplets with non-zero integer ambiguity of the closure phase (section 3.2 in Yunjun et al., 2019). It provides a distribution map (pixels with non-zero values) of phase unwrapping errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep quick_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('avgPhaseVelocity.h5'.split())     # plot the stacking result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mintpy.unwrap_error_phase_closure import plot_num_triplet_with_nonzero_integer_ambiguity\n",
    "plot_num_triplet_with_nonzero_integer_ambiguity('numTriNonzeroIntAmbiguity.h5', display=True, fig_size=[12, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Phase-unwrapping error correction (optional) ###\n",
    "\n",
    "This step corrects phase-unwrapping errors in the stack of interferograms, supporting the following methods (Yunjun et al., 2019):   \n",
    "+ bridging\n",
    "+ phase_closure\n",
    "+ bridging+phase_closure    \n",
    "    \n",
    "If turn on, it will add new dataset named as \"unwrapPhase_bridging\" or \"unwrapPhase_phaseClosure\" or \"unwrapPhase_bridging_phaseClosure\" into the ./inputs/ifgramStack.h5 file. The corresonding template options are:\n",
    "\n",
    "```cfg\n",
    "########## 4. correct_unwrap_error (optional)\n",
    "## connected components (mintpy.load.connCompFile) are required for this step.\n",
    "## reference: Yunjun et al. (2019, section 3)\n",
    "## supported methods:\n",
    "## a. phase_closure           - suitable for highly redundant network\n",
    "## b. bridging                - suitable for islands or areas with steep topography\n",
    "## c. bridging+phase_closure  - recommended\n",
    "mintpy.unwrapError.method          = auto  #[bridging / phase_closure / bridging+phase_closure / no], auto for no\n",
    "mintpy.unwrapError.waterMaskFile   = auto  #[waterMask.h5 / no], auto for waterMask.h5 or no [if no waterMask.h5 found]\n",
    "\n",
    "## briding options:\n",
    "## ramp - a phase ramp could be estimated based on the largest reliable region, removed from the entire interferogram\n",
    "##        before estimating the phase difference between reliable regions and added back the correction.\n",
    "## bridgePtsRadius - half size of the window used to calculate the median value of phase difference\n",
    "mintpy.unwrapError.ramp            = auto  #[linear / quadratic], auto for no; recommend linear for L-band data\n",
    "mintpy.unwrapError.bridgePtsRadius = auto  #[1-inf], auto for 50, half size of the window around end points\n",
    "```\n",
    "\n",
    "In this dataset, we turn off (by default) this option and skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Network inversion ###\n",
    "\n",
    "This step inverts the network of interferograms for the raw phase time-series. Note that this raw phase time-series includes contributions from ground deformation, atmospheric delay and topographic residual caused by DEM error. The following **weighted least squares (WLS) inversions** methods are supported:\n",
    "\n",
    "+ Inverse of covariance\n",
    "+ Finisher Information Matrix (FIM)\n",
    "+ Spatial coherence\n",
    "+ Uniform / no weighting\n",
    "\n",
    "The corresponding template options are:   \n",
    "\n",
    "```cfg\n",
    "## Invert network of interferograms into time-series using weighted least sqaure (WLS) estimator.\n",
    "## weighting options for least square inversion [fast option available but not best]:\n",
    "## a. var - use inverse of covariance as weight (Tough et al., 1995; Guarnieri & Tebaldini, 2008) [recommended]\n",
    "## b. fim - use Fisher Information Matrix as weight (Seymour & Cumming, 1994; Samiei-Esfahany et al., 2016).\n",
    "## c. coh - use coherence as weight (Perissin & Wang, 2012)\n",
    "## d. no  - uniform weight (Berardino et al., 2002) [fast]\n",
    "## SBAS (Berardino et al., 2002) = minNormVelocity (yes) + weightFunc (no)\n",
    "mintpy.networkInversion.weightFunc      = auto #[var / fim / coh / no], auto for var\n",
    "mintpy.networkInversion.waterMaskFile   = auto #[filename / no], auto for waterMask.h5 or no [if not found]\n",
    "mintpy.networkInversion.minNormVelocity = auto #[yes / no], auto for yes, min-norm deformation velocity / phase\n",
    "mintpy.networkInversion.residualNorm    = auto #[L2 ], auto for L2, norm minimization solution\n",
    "\n",
    "## mask options for unwrapPhase of each interferogram before inversion (recommed if weightFunct=no):\n",
    "## a. coherence        - mask out pixels with spatial coherence < maskThreshold\n",
    "## b. connectComponent - mask out pixels with False/0 value\n",
    "## c. no               - no masking [recommended].\n",
    "## d. offsetSNR        - mask out pixels with offset SNR < maskThreshold [for offset]\n",
    "mintpy.networkInversion.maskDataset   = auto #[coherence / connectComponent / offsetSNR / no], auto for no\n",
    "mintpy.networkInversion.maskThreshold = auto #[0-inf], auto for 0.4\n",
    "mintpy.networkInversion.minRedundancy = auto #[1-inf], auto for 1.0, min num_ifgram for every SAR acquisition\n",
    "\n",
    "## Parallel processing with Dask\n",
    "## Notes for \"local\" cluster:\n",
    "## 1) no job scheduler is required to install on the cluster\n",
    "## 2) no walltime or config is required to set\n",
    "## 3) \"numWorker = all\" is for local cluster only, to use all local available resources.\n",
    "mintpy.networkInversion.parallel  = auto #[yes / no], auto for no, parallel processing using dask\n",
    "mintpy.networkInversion.cluster   = auto #[slurm / pbs / lsf / local], auto for local, cluster type\n",
    "mintpy.networkInversion.config    = auto #[slurm / pbs / lsf / no], auto for no (same as cluster), config name\n",
    "mintpy.networkInversion.numWorker = auto #[int > 1 / all], auto for 4 (local) or 40 (non-local), num of workers\n",
    "mintpy.networkInversion.walltime  = auto #[HH:MM], auto for 00:40, walltime for each dask worker\n",
    "\n",
    "## Temporal coherence is calculated and used to generate the mask as the reliability measure\n",
    "## reference: Pepe & Lanari (2006, IEEE-TGRS)\n",
    "mintpy.networkInversion.minTempCoh  = auto #[0.0-1.0], auto for 0.7, min temporal coherence for mask\n",
    "mintpy.networkInversion.minNumPixel = auto #[int > 1], auto for 100, min number of pixels in mask above\n",
    "mintpy.networkInversion.shadowMask  = auto #[yes / no], auto for yes [if shadowMask is in geometry file] or no.\n",
    "```\n",
    "\n",
    "It outputs the following files:   \n",
    "\n",
    "```cfg\n",
    "timeseries.h5         #raw phase time-series in unit of meters.\n",
    "temporalCoherence.h5  #temporal coherence (Pepe et al., 2006).\n",
    "maskTempCoh.h5        #mask of reliable pixels with min temporal coherence of \"minTempCoh\" value.\n",
    "numInvIfgram.h5       #number of interferograms used in the inversion for each pixel.\n",
    "                      #This number varies for different pixels if \"maskDataset\" is not \"no\".\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep invert_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the raw phase time-series and re-wrapped into [-5, 5) cm\n",
    "view.main('timeseries.h5 --wrap --wrap-range -5 5 -u cm --notitle --notick --noaxis'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!date\n",
    "view.main('temporalCoherence.h5 --notick --noaxis --noverbose'.split())\n",
    "view.main('maskTempCoh.h5 --notick --noaxis --noverbose'.split())\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Correct local oscillator drift (for Envisat) ###\n",
    "\n",
    "Data from Envisatâ€™s Advanced Synthetic Aperture Radar (ASAR) instrument include a phase ramp in range direction due to timing errors. This step corrects the local oscillator drift using the empirical model given by Marinkovic and Larsen (2013). It's automatically turned ON for Envisat data and OFF for all the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep correct_LOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Tropospheric delay correction ###\n",
    "\n",
    "This step corrects the tropospheric phase delay. Two methods are supported:\n",
    "\n",
    "+ Global Atmospheric Models (GAMs) (Jolivet et al., 2011; 2014; PyAPS needs to be installed).\n",
    "+ Empirical relationship between stratified tropospheric delay and topography (Doin et al., 2009).\n",
    "\n",
    "The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "## correct tropospheric delay using the following methods:\n",
    "## a. height_correlation - correct stratified tropospheric delay (Doin et al., 2009, J Applied Geop)\n",
    "## b. pyaps - use Global Atmospheric Models (GAMs) data (Jolivet et al., 2011; 2014)\n",
    "##      ERA5  - ERA-5       from ECMWF [need to install pyaps3 on GitHub; recommended and turn ON by default]\n",
    "##      ECMWF - ERA-Interim from ECMWF [need to install pyaps  on Caltech/EarthDef]\n",
    "##      MERRA - MERRA-2     from NASA  [need to install pyaps  on Caltech/EarthDef]\n",
    "##      NARR  - NARR        from NOAA  [need to install pyaps  on Caltech/EarthDef; recommended for N America]\n",
    "mintpy.troposphericDelay.method = auto  #[pyaps / height_correlation / no], auto for pyaps\n",
    "\n",
    "## Notes for pyaps:\n",
    "## a. GAM data latency: with the most recent SAR data, there will be GAM data missing, the correction\n",
    "##    will be applied to dates with GAM data available and skipped for the others.\n",
    "## b. WEATHER_DIR: if you define an environmental variable named WEATHER_DIR to contain the path to a\n",
    "##    directory, then MintPy applications will download the GAM files into the indicated directory. \n",
    "##    MintPy application will look for the GAM files in the directory before downloading a new one to\n",
    "##    prevent downloading multiple copies if you work with different dataset that cover the same date/time.\n",
    "mintpy.troposphericDelay.weatherModel = auto  #[ERA5 / ECMWF / MERRA / NARR], auto for ERA5\n",
    "mintpy.troposphericDelay.weatherDir   = auto  #[path2directory], auto for WEATHER_DIR or \"./\"\n",
    "\n",
    "## Notes for height_correlation:\n",
    "## Extra multilooking is applied to estimate the empirical phase/elevation ratio ONLY.\n",
    "## For an dataset with 5 by 15 looks, looks=8 will generate phase with (5*8) by (15*8) looks\n",
    "## to estimate the empirical parameter; then apply the correction to original phase (with 5 by 15 looks),\n",
    "## if the phase/elevation correlation is larger than minCorrelation.\n",
    "mintpy.troposphericDelay.polyOrder      = auto  #[1 / 2 / 3], auto for 1\n",
    "mintpy.troposphericDelay.looks          = auto  #[1-inf], auto for 8, extra multilooking num\n",
    "mintpy.troposphericDelay.minCorrelation = auto  #[0.0-1.0], auto for 0\n",
    "```\n",
    "\n",
    "It outputs:\n",
    "+ timeseries_ECMWF.h5: the troposphere-corrected time-series (ECMWF data is selected in this case).\n",
    "+ ECMWF.h5: the estimated tropospheric phase delay time-series (for pyaps method only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep correct_troposphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('timeseries_ERA5.h5 --notitle --wrap --wrap-range -5 5 --notick --noaxis'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Phase deramping (optional) ###\n",
    "\n",
    "This step estimate and remove a linear or quadratic ramp for each acquisition based on the phase of the reliable pixels. It's recommended for localized deformation signals, such as volcanic deformation, landslides and city subsidence; but not recommeded for long spatial wavelength deformation signals, such as interseismic deformation.\n",
    "\n",
    "The cooresponding template options are:\n",
    "\n",
    "```cfg\n",
    "## estimate and remove a phase ramp for each acquisition based on the reliable pixels.\n",
    "## recommended for localized deformation signals, i.e. volcanic deformation, landslide and subsidence, etc.\n",
    "mintpy.deramp          = auto  #[no / linear / quadratic], auto for no - no ramp will be removed\n",
    "mintpy.deramp.maskFile = auto  #[filename / no], auto for maskTempCoh.h5, mask file for ramp estimation\n",
    "```\n",
    "\n",
    "It outputs a new time-series HDF5 file with suffix _ramp_: timeseries_ECMWF_ramp.h5 in this example case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep deramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('timeseries_ERA5_ramp.h5 --notitle --wrap --wrap-range -5 5 --notick --noaxis'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Topographic residual (DEM error) correction ###\n",
    "\n",
    "This step corrects the phase residual caused by the inaccuracy of DEM (DEM error) using its relationship with the perpendicular baseline time-series (Fattahi and Amelung, 2013, IEEE-TGRS). The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "## reference: Fattahi and Amelung, 2013, IEEE-TGRS\n",
    "## Notes on options:\n",
    "## stepFuncDate      - Specify stepFuncDate option if you know there are sudden displacement jump in your area,\n",
    "##    i.e. volcanic eruption, or earthquake, and check timeseriesStepModel.h5 afterward for their estimation.\n",
    "## excludeDate       - Dates excluded for error estimation only\n",
    "## pixelwiseGeometry - Use pixel-wise geometry info, such as incidence angle and slant range distance for error estimation\n",
    "##    yes - use pixel-wise geometry when they are available [slow; used by default]\n",
    "##    no  - use mean geometry [fast]\n",
    "mintpy.topographicResidual                    = auto  #[yes / no], auto for yes\n",
    "mintpy.topographicResidual.polyOrder          = auto  #[1-inf], auto for 2, poly order of temporal deformation model\n",
    "mintpy.topographicResidual.phaseVelocity      = auto  #[yes / no], auto for no - phase, use phase velocity for error estimation\n",
    "mintpy.topographicResidual.stepFuncDate       = auto  #[20080529,20100611 / no], auto for no, date of step jump\n",
    "mintpy.topographicResidual.excludeDate        = auto  #[20070321 / txtFile / no], auto for exclude_date.txt\n",
    "mintpy.topographicResidual.pixelwiseGeometry  = auto  #[yes / no], auto for yes, use pixel-wise geometry info\n",
    "```\n",
    "\n",
    "It outputs:\n",
    "+ timeseries_ECMWF_ramp_demErr.h5: the topographic residual corrected time-series.\n",
    "+ timeseriesResidual.h5: residual phase time-series of this least square inversion.\n",
    "+ demErr.h5: the estimated DEM error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep correct_topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('timeseries_ERA5_ramp_demErr.h5 --notitle --wrap --wrap-range -5 5 --notick --noaxis'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 Phase residual RMS for noise evaluation ###\n",
    "\n",
    "This step calculates the Root Mean Square (RMS) of the residual phase time-series for each acquisition; then it:\n",
    "1. selects the date with the minimum RMS value as the optimal reference date.\n",
    "2. detects the noisy acquisitions with RMS beyond the outlier detection threshold.\n",
    "\n",
    "The corresponding template options are:\n",
    "```cfg\n",
    "## 1) Residual Phase Root Mean Square\n",
    "## calculate the Root Mean Square (RMS) of residual phase time-series for each acquisition\n",
    "## To get rid of long wavelength component in space, a ramp is removed for each acquisition\n",
    "## Set optimal reference date to date with min RMS\n",
    "## Set exclude dates (outliers) to dates with RMS > cutoff * median RMS (Median Absolute Deviation)\n",
    "mintpy.residualRMS.maskFile = auto  #[file name / no], auto for maskTempCoh.h5, mask for ramp estimation\n",
    "mintpy.residualRMS.deramp   = auto  #[quadratic / linear / no], auto for quadratic\n",
    "mintpy.residualRMS.cutoff   = auto  #[0.0-inf], auto for 3\n",
    "```\n",
    "\n",
    "It outputs:\n",
    "+ rms_timeseriesResidual_ramp.txt: for RMS value of each acquisition\n",
    "+ rms_timeseriesResidual_ramp.pdf: plot of the rms_timeseriesResidual_ramp.txt\n",
    "+ reference_date.txt: date in YYYYMMDD format for the optional reference date\n",
    "+ exclude_date.txt: date(s) in YYYYMMDD format for the noisy acquisitions (if at least one is detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep residual_RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head rms_timeseriesResidual_ramp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat reference_date.txt    #auto selected optimal reference date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the RMS value\n",
    "from mintpy.timeseries_rms import plot_rms_bar\n",
    "txtContent = np.loadtxt('./rms_timeseriesResidual_ramp.txt', dtype=bytes).astype(str)\n",
    "rms_list = [float(i) for i in txtContent[:, 1]]\n",
    "date_list = [i for i in txtContent[:, 0]]\n",
    "fig, ax = plt.subplots(figsize=[10, 4])\n",
    "ax = plot_rms_bar(ax, date_list, rms_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.12 Change reference date ###\n",
    "\n",
    "This step changes the reference date of all phase time-series files, based on the input template option:\n",
    "\n",
    "```cfg\n",
    "## reference all time-series to one date in time\n",
    "## no     - do not change the default reference date (1st date)\n",
    "mintpy.reference.date  = auto   #[reference_date.txt / 20090214 / no], auto for reference_date.txt\n",
    "```\n",
    "\n",
    "This step operates on the existing time-series files and does not output new files.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> \n",
    "The optimal reference date (default option) gives the time-series plot a \"clean\" looks only. Changing the reference is equivalent to adding a constant to the displacement time series, which does not change the velocity or any other information derived from the displacement time series.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep reference_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 Velocity\n",
    "\n",
    "This step estimates the average velocity as the slope of the best fitting line to the displacement time-series and its standard deviation, given by equation (10) in Fattahi and Amelung (2015, JGR). Noisy acquisitions (identified in \"residual_RMS\" step) from exclude_date.txt file are excluded by default during the estimation. \n",
    "\n",
    "The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "## estimate linear velocity from time-series, and from tropospheric delay file if exists.\n",
    "mintpy.velocity.excludeDate = auto   #[exclude_date.txt / 20080520,20090817 / no], auto for exclude_date.txt\n",
    "mintpy.velocity.startDate   = auto   #[20070101 / no], auto for no\n",
    "mintpy.velocity.endDate     = auto   #[20101230 / no], auto for no\n",
    "```\n",
    "\n",
    "It outputs:\n",
    "+ velocity.h5: the estimated average velocity and its standard deviation from displacement time-series.\n",
    "+ velocityECMWF.h5: same as above but from the tropospheric delay time-series, to see the potential bias introduced by troposphere if it was not corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!info.py velocity.h5 --compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('velocity.h5 --notick --noaxis --noverbose'.split())\n",
    "view.main('velocityERA5.h5 --notick --noaxis --noverbose'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Geocoding (optional) ###\n",
    "\n",
    "This step resamples the following files from radar coordinates to geo coordinates. It's skipped if input dataset is in geo coordiantes already. The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "mintpy.geocode              = auto  #[yes / no], auto for yes\n",
    "mintpy.geocode.SNWE         = auto  #[-1.2,0.5,-92,-91 / no ], auto for no, coverage in S N W E in degree\n",
    "mintpy.geocode.latStep      = auto  #[0.0-90.0 / None], auto for None (calculate from lookup file)\n",
    "mintpy.geocode.lonStep      = auto  #[0.0-180.0 / None], auto for None (calculate from lookup file)\n",
    "mintpy.geocode.interpMethod = auto  #[nearest], auto for nearest, interpolation method\n",
    "mintpy.geocode.fillValue    = auto  #[np.nan, 0, ...], auto for np.nan, fill value for outliers.\n",
    "```\n",
    "\n",
    "It outputs the following files into **./geo** folder:\n",
    "+ ./geo/geo_geometryRadar.h5\n",
    "+ ./geo/geo_maskTempCoh.h5\n",
    "+ ./geo/geo_temporalCoherence.h5\n",
    "+ ./geo/geo_timeseries_ECMWF_ramp_demErr.h5\n",
    "+ ./geo/geo_velocity.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ./geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main('./geo/geo_velocity.h5 velocity --dem ./geo/geo_geometryRadar.h5 --figsize 12 12 --notick --noaxis'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.15 Output to Google Earth format (optional)\n",
    "\n",
    "This step saves the geocoded velocity to the .kmz format. The corresponding template option is:  \n",
    "\n",
    "```cfg\n",
    "mintpy.save.kmz             = auto   #[yes / no], auto for yes, save geocoded velocity to Google Earth KMZ file\n",
    "```\n",
    "\n",
    "It output the ./geo/geo_velocity.kmz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py FernandinaSenDT128.txt --dostep google_earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step isn't available.\n",
    "\n",
    "!open ./geo/geo_velocity.kmz   #Open KMZ file in Google Earth, which needs to be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.16 Save to HDF-EOS5 format (optional)\n",
    "\n",
    "This step saves the geocoded displacement time-series into [HDF-EOS5](https://earthdata.nasa.gov/user-resources/standards-and-references/hdf-eos5) format. It is well-suited for **data sharing**. This format is used in University of Miami's insarmaps website: https://insarmaps.miami.edu.\n",
    "\n",
    "The corresponding template options are:\n",
    "\n",
    "```cfg\n",
    "mintpy.save.hdfEos5         = auto   #[yes / no], auto for no, save time-series to HDF-EOS5 format\n",
    "mintpy.save.hdfEs5.update   = auto   #[yes / no], auto for no, put XXXXXXXX as endDate in output filename\n",
    "mintpy.save.hdfEos5.subset  = auto   #[yes / no], auto for no, put subset range info   in output filename\n",
    "```\n",
    "\n",
    "The output file includes 3D displacement time-series, temporal coherence, temporal coherence mask and all geometry related dataset: height, incidenceAngle, slantRangeDistance etc. For details on the naming convention and dataset structure, check the wiki page [here](https://github.com/insarlab/MintPy/wiki/HDF-EOS5). For this example dataset, it would output a file: S1_IW12_128_0593_0597_20141213_20180619.he5 if turn on. However, it's turn off and skipped here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. smallbaselineApp.py non-stop processing\n",
    "\n",
    "Once the user gets familiar with the template setting, one can setup all the custom modified configurations (in the custom template file - recommeded), and run smallbaselineApp.py with a single command-line call to process all steps:\n",
    "\n",
    "```\n",
    "smallbaselineApp.py FernandinaSenDT128.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Re-run and skipping of processing steps\n",
    "\n",
    "To facilitate the re-running process, a skipping strategy is implemented for all steps in smallbaselineApp.py and skip steps if:\n",
    "\n",
    "1. output files / datasets already exist and are newer than input files / datasets \n",
    "2. AND for key / time-consuming steps (unwrap error correction, network inversion, topographic residual correction, etc.):     \n",
    "    all related configurations are the same as before.\n",
    "\n",
    "Therefore, one can modified the template option and re-run smallbaselineApp.py without specifying the start/end step, and the processing will start from where is changed and continue from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Move ./inputs after runing `smallbaselineApp.py --end load_data`\n",
    "\n",
    "**./inputs** folder contains everything smallbaselineApp.py needs. One can move the ./inputs folder to anywhere MintPy is installed and re-start the whole analysis. It's well-suited for users who want to play around the analysis on their local laptop after the massive InSAR stack processing on the High Performance Computer (HPC) or Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant references:\n",
    "\n",
    "+ Berardino, P., G. Fornaro, R. Lanari, and E. Sansosti (2002), A new algorithm for surface deformation monitoring based on small baseline differential SAR interferograms, Geoscience and Remote Sensing, IEEE Transactions on, 40(11), 2375-2383, doi:10.1109/TGRS.2002.803792.\n",
    "\n",
    "+ Chaussard, E., F. Amelung, and Y. Aoki (2013), Characterization of open and closed volcanic systems in Indonesia and Mexico using InSAR time series, Journal of Geophysical Research: Solid Earth, 118(8), 3957-3969, doi:10.1002/jgrb.50288.\n",
    "\n",
    "+ Chen, C. W., and H. A. Zebker (2001), Two-dimensional phase unwrapping with use of statistical models for cost functions in nonlinear optimization, JOSA A, 18(2), 338-351, doi:10.1364/JOSAA.18.000338.\n",
    "\n",
    "+ Doin, M. P., C. Lasserre, G. Peltzer, O. CavaliÃ©, and C. Doubre (2009), Corrections of stratified tropospheric delays in SAR interferometry: Validation with global atmospheric models, Journal of Applied Geophysics, 69(1), 35-50, doi:10.1016/j.jappgeo.2009.03.010.\n",
    "\n",
    "+ Fattahi, H., and F. Amelung (2013), DEM Error Correction in InSAR Time Series, Geoscience and Remote Sensing, IEEE Transactions on, 51(7), 4249-4259, doi:10.1109/TGRS.2012.2227761.\n",
    "\n",
    "+ Fattahi, H., and F. Amelung (2015), InSAR bias and uncertainty due to the systematic and stochastic tropospheric delay, Journal of Geophysical Research: Solid Earth, 120(12), 8758-8773, doi:10.1002/2015JB012419.\n",
    "\n",
    "+ Fattahi, H., P. Agram, and M. Simons (2016), A Network-Based Enhanced Spectral Diversity Approach for TOPS Time-Series Analysis, IEEE Transactions on Geoscience and Remote Sensing, 55(2), 777-786, doi:10.1109/TGRS.2016.2614925.\n",
    "\n",
    "+ Jolivet, R., R. Grandin, C. Lasserre, M. P. Doin, and G. Peltzer (2011), Systematic InSAR tropospheric phase delay corrections from global meteorological reanalysis data, Geophysical Research Letters, 38(17), L17311, doi:10.1029/2011GL048757.\n",
    "\n",
    "+ Marinkovic, P., and Y. Larsen (2013), Consequences of long-term ASAR local oscillator frequency decay - An empirical study of 10 years of data, paper presented at Proceedings of the Living Planet Symposium (abstract), European Space Agency, Edinburgh, U. K.\n",
    "\n",
    "+ Morales Rivera, A. M., F. Amelung, and P. Mothes (2016), Volcano Deformation Survey over the Northern and Central Andes with ALOS InSAR Time Series, Geochemistry, Geophysics, Geosystems, 17, 2869-2883, doi:10.1002/2016GC006393.\n",
    "\n",
    "+ Pepe, A., and R. Lanari (2006), On the extension of the minimum cost flow algorithm for phase unwrapping of multitemporal differential SAR interferograms, Geoscience and Remote Sensing, IEEE Transactions on, 44(9), 2374-2383, doi:10.1109/TGRS.2006.873207.\n",
    "\n",
    "+ Rosen, P. A., S. Hensley, G. Peltzer, and M. Simons (2004), Updated repeat orbit interferometry package released, Eos Trans. AGU, 85(5), 47-47, doi:10.1029/2004EO050004.\n",
    "\n",
    "+ Rosen, P. A., E. Gurrola, G. F. Sacco, and H. Zebker (2012), The InSAR scientific computing environment, paper presented at EUSAR 2012, 23-26 April 2012.\n",
    "\n",
    "+ Werner, C., U. WegmÃ¼ller, T. Strozzi, and A. Wiesmann (2000), Gamma SAR and interferometric processing software, paper presented at Proceedings of the ERS-Envisat symposium, Gothenburg, Sweden.\n",
    "\n",
    "+ Yunjun, Z., H. Fattahi, F. Amelung (2019), Small baseline InSAR time series analysis: Unwrapping error correction and noise reduction, Computers & Geosciences, 133, 104331, doi:10.1016/j.cageo.2019.104331.\n",
    "\n",
    "+ Zebker, H. A., P. A. Rosen, and S. Hensley (1997), Atmospheric effects in interferometric synthetic aperture radar surface deformation and topographic maps, Journal of Geophysical Research: Solid Earth, 102(B4), 7547-7563, doi:10.1029/96JB03804."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\">This notebook is compatible with NISAR Jupyter Server Stack v1.4 and above</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mintpy",
   "language": "python",
   "name": "mintpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
